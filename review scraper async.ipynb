{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abhyu\\Desktop\\Cabinet\\review scraper\\review scraper async.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 63>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhyu/Desktop/Cabinet/review%20scraper/review%20scraper%20async.ipynb#W0sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mprint\u001b[39m(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhyu/Desktop/Cabinet/review%20scraper/review%20scraper%20async.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/abhyu/Desktop/Cabinet/review%20scraper/review%20scraper%20async.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     asyncio\u001b[39m.\u001b[39;49mrun(main())\n",
      "File \u001b[1;32mc:\\Users\\abhyu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m coroutines\u001b[39m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39ma coroutine was expected, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "all_reviews = 0\n",
    "url = \"https://letterboxd.com/film/beijing-watermelon/\"\n",
    "url = url + \"/reviews/by/activity/page/\"\n",
    "keyword = \"cinema\"\n",
    "\n",
    "async def fetch_page(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def parse_page(url, session):\n",
    "    html = await fetch_page(session, url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "async def collect_data(review_item, keyword):\n",
    "    review_text = review_item.find('div', class_=\"body-text -prose collapsible-text\").text\n",
    "    if review_text.endswith('...'):\n",
    "        review_text = await parse_page(full_review_url, session)\n",
    "    \n",
    "    relevance = keyword in review_text\n",
    "\n",
    "    if relevance:\n",
    "        full_review_url = \"https://letterboxd.com\" + review_item.find('div', class_=\"body-text -prose collapsible-text\")['data-full-text-url']\n",
    "\n",
    "        try:\n",
    "            rating = review_item.find('span', class_=lambda value: value and 'rated' in value).text\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        return [full_review_url, rating, review_text]\n",
    "\n",
    "    return None\n",
    "\n",
    "async def get_reviews_page(page_url, keyword, session):\n",
    "    page = await parse_page(page_url, session)\n",
    "    all_reviews = page.find_all('div', {'class': 'film-detail-content'})\n",
    "    review_data = [collect_data(review, keyword) for review in all_reviews]\n",
    "    return [data for data in review_data if data is not None]\n",
    "\n",
    "async def get_reviews(url, keyword):\n",
    "    all_review_data = pd.DataFrame(columns=['URL', 'Rating', 'Review'])\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i in range(1, 100):  # Adjust the range accordingly\n",
    "            page_url = url + str(i)\n",
    "            reviews = await get_reviews_page(page_url, keyword, session)\n",
    "            if not reviews:\n",
    "                break\n",
    "\n",
    "            df_row = pd.DataFrame(reviews, columns=['URL', 'Rating', 'Review'])\n",
    "            all_review_data = pd.concat([all_review_data, df_row])\n",
    "\n",
    "    return all_review_data\n",
    "\n",
    "async def main():\n",
    "    data = await get_reviews(url=url, keyword=keyword)\n",
    "    print(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
